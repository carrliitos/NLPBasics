{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/carlitos/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2b8c52939f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/carlitos/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/carlitos/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization: \n",
      "Backgammon is one of the oldest known board games.\n",
      "\n",
      "Word Tokenization: \n",
      "['Backgammon', 'is', 'one', 'of', 'the', 'oldest', 'known', 'board', 'games', '.']\n",
      "\n",
      "Sentence Tokenization: \n",
      "Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East.\n",
      "\n",
      "Word Tokenization: \n",
      "['Its', 'history', 'can', 'be', 'traced', 'back', 'nearly', '5,000', 'years', 'to', 'archeological', 'discoveries', 'in', 'the', 'Middle', 'East', '.']\n",
      "\n",
      "Sentence Tokenization: \n",
      "It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\n",
      "\n",
      "Word Tokenization: \n",
      "['It', 'is', 'a', 'two', 'player', 'game', 'where', 'each', 'player', 'has', 'fifteen', 'checkers', 'which', 'move', 'between', 'twenty-four', 'points', 'according', 'to', 'the', 'roll', 'of', 'two', 'dice', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(\"Sentence Tokenization: \")\n",
    "    print(sentence)\n",
    "    print()\n",
    "    \n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    print(\"Word Tokenization: \")\n",
    "    print(words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"However, we still can have problems if we only split by space to achieve the wanted results. Some English compound nouns are variably written and sometimes they contain a space. In most cases, we use a library to achieve the wanted results, so again don’t worry too much for the details.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['However', ',', 'we', 'still', 'can', 'have', 'problems', 'if', 'we', 'only', 'split', 'by', 'space', 'to', 'achieve', 'the', 'wanted', 'results', '.']\n",
      "\n",
      "['Some', 'English', 'compound', 'nouns', 'are', 'variably', 'written', 'and', 'sometimes', 'they', 'contain', 'a', 'space', '.']\n",
      "\n",
      "['In', 'most', 'cases', ',', 'we', 'use', 'a', 'library', 'to', 'achieve', 'the', 'wanted', 'results', ',', 'so', 'again', 'don', '’', 't', 'worry', 'too', 'much', 'for', 'the', 'details', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    print(words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"A 25-year-old male camel caregiver presented to the Emergency Department of Al-Ain Hospital 1 h after being bitten several times in the left side of his head and neck by a 15-year-old male camel. The injury occurred in the farm while the patient was trying to feed the camel. The camel turned aggressive and strongly and repeatedly gripped the patient's face between its jaws, lifting the patient up in the air while shaking and throwing him forcefully to the ground. These bites were repeated four times to the patient's face and neck. The patient was able to rescue himself only after putting his headscarf inside the camel's mouth. On clinical examination, the patient was fully conscious, alert, but in severe distress. His blood pressure was 159/91 mm Hg. Pulse rate was 47 beats per minute, and body temperature was 36.5 °C. There were multiple puncture and laceration wounds on the left side of his face and neck (Fig. 1). Inspection of the facial wounds showed a swollen left eye with lacerations on the eyelid and eyebrow with extensive sub-conjunctival hemorrhage. An approximately 13 cm lacerated wound on the left side of the face extended from the temporal region to the left chin with surrounding skin erythema. There was bleeding from the left ear with a laceration of the crus of the left helix. Neck inspection showed a 7 cm laceration in the left submandibular area with no obvious injury to the adjacent great vessels (Fig. 1). The patient was given 0.5 ml of tetanus toxoid vaccine intramuscularly and was admitted to the hospital. A trauma computed tomography (CT) was performed to detect other injuries. Maxillofacial CT without contrast showed a comminuted fracture of the left nasal bone, a fracture of the medial orbital wall with sagging of medial rectus muscle into the fracture space, medial rectus muscle hematoma, fracture of lacrimal bone and displacement of piece of it into the orbit, left preseptal hematoma, complete opaciﬁcation of left intraocular content, crystalline lens was not identiﬁed, and the eye appeared as one chamber with loss of the eyewall integrity (Fig. 2). Although the left optic nerve appeared stretched, there were no obvious CT ﬁndings for its injury. CT angiographic study of the neck arteries showed no evidence of active extravasation, dissection or thrombosis. Prophylactic antibiotic using intravenous ceftriaxone and metronidazole was commenced. The patient was taken to the operation room, and the wounds were explored and debrided under general anesthesia. Upper lid (2 cm) full thickness laceration, eyebrow (3.5 cm), lateral to lateral canthal area laceration and inferior bulbar conjunctiva were repaired. There was a massive corneal laceration with expulsion of the eye content. Salvaging the left eye was not possible, and evisceration of the eye was performed. Intraoperative examination of the left cheek wound site (Fig. 3) revealed macerated muscle with a deep wound penetrating the underlying superﬁcial musculoaponeurotic system. The left Parotid duct was partially transected over the masseter muscle (Fig. 3). This was approximated and primarily repaired using Nylon 8/0 sutures, and the parotid gland capsule was also sutured. The buccal branch of the facial nerve could not be identiﬁed. The nasal bone fracture was managed with closed reduction. The lacerations of the left auricle and the left submandibular region were closed in layers. On a postoperative day 6, the patient developed a small left-sided sialocele which has rapidly progressed into a ﬁstula. This was managed with Hyoscine tablets, transdermal scopolamine, and pressure dressing. A favorable response was observed after three days. The patient was discharged home on day 9 in a good general condition and was placed on Clindamycin 600 mg 4 times a day, Hyoscine 20 mg 3 times a day, and Erythromycin 0.5% ophthalmic ointment. A follow up at one month showed a satisfactory scar, completely healed salivary ﬁstula, and a residual weak upper lip function. The patient gave written informed consent for publication of his clinical images in this manuscript.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSentences = nltk.sent_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4b6b2ee4b05f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewSentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewSentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \"\"\"\n\u001b[0;32m-> 1272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \"\"\"\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \"\"\"\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \"\"\"\n\u001b[1;32m   1356\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after_tok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "for sentence in newSentences:\n",
    "    words = nltk.word_tokenize(newSentences)\n",
    "    print(words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', '25-year-old', 'male', 'camel', 'caregiver', 'presented', 'to', 'the', 'Emergency', 'Department', 'of', 'Al-Ain', 'Hospital', '1', 'h', 'after', 'being', 'bitten', 'several', 'times', 'in', 'the', 'left', 'side', 'of', 'his', 'head', 'and', 'neck', 'by', 'a', '15-year-old', 'male', 'camel', '.']\n",
      "\n",
      "['The', 'injury', 'occurred', 'in', 'the', 'farm', 'while', 'the', 'patient', 'was', 'trying', 'to', 'feed', 'the', 'camel', '.']\n",
      "\n",
      "['The', 'camel', 'turned', 'aggressive', 'and', 'strongly', 'and', 'repeatedly', 'gripped', 'the', 'patient', \"'s\", 'face', 'between', 'its', 'jaws', ',', 'lifting', 'the', 'patient', 'up', 'in', 'the', 'air', 'while', 'shaking', 'and', 'throwing', 'him', 'forcefully', 'to', 'the', 'ground', '.']\n",
      "\n",
      "['These', 'bites', 'were', 'repeated', 'four', 'times', 'to', 'the', 'patient', \"'s\", 'face', 'and', 'neck', '.']\n",
      "\n",
      "['The', 'patient', 'was', 'able', 'to', 'rescue', 'himself', 'only', 'after', 'putting', 'his', 'headscarf', 'inside', 'the', 'camel', \"'s\", 'mouth', '.']\n",
      "\n",
      "['On', 'clinical', 'examination', ',', 'the', 'patient', 'was', 'fully', 'conscious', ',', 'alert', ',', 'but', 'in', 'severe', 'distress', '.']\n",
      "\n",
      "['His', 'blood', 'pressure', 'was', '159/91', 'mm', 'Hg', '.']\n",
      "\n",
      "['Pulse', 'rate', 'was', '47', 'beats', 'per', 'minute', ',', 'and', 'body', 'temperature', 'was', '36.5', '°C', '.']\n",
      "\n",
      "['There', 'were', 'multiple', 'puncture', 'and', 'laceration', 'wounds', 'on', 'the', 'left', 'side', 'of', 'his', 'face', 'and', 'neck', '(', 'Fig', '.']\n",
      "\n",
      "['1', ')', '.']\n",
      "\n",
      "['Inspection', 'of', 'the', 'facial', 'wounds', 'showed', 'a', 'swollen', 'left', 'eye', 'with', 'lacerations', 'on', 'the', 'eyelid', 'and', 'eyebrow', 'with', 'extensive', 'sub-conjunctival', 'hemorrhage', '.']\n",
      "\n",
      "['An', 'approximately', '13', 'cm', 'lacerated', 'wound', 'on', 'the', 'left', 'side', 'of', 'the', 'face', 'extended', 'from', 'the', 'temporal', 'region', 'to', 'the', 'left', 'chin', 'with', 'surrounding', 'skin', 'erythema', '.']\n",
      "\n",
      "['There', 'was', 'bleeding', 'from', 'the', 'left', 'ear', 'with', 'a', 'laceration', 'of', 'the', 'crus', 'of', 'the', 'left', 'helix', '.']\n",
      "\n",
      "['Neck', 'inspection', 'showed', 'a', '7', 'cm', 'laceration', 'in', 'the', 'left', 'submandibular', 'area', 'with', 'no', 'obvious', 'injury', 'to', 'the', 'adjacent', 'great', 'vessels', '(', 'Fig', '.']\n",
      "\n",
      "['1', ')', '.']\n",
      "\n",
      "['The', 'patient', 'was', 'given', '0.5', 'ml', 'of', 'tetanus', 'toxoid', 'vaccine', 'intramuscularly', 'and', 'was', 'admitted', 'to', 'the', 'hospital', '.']\n",
      "\n",
      "['A', 'trauma', 'computed', 'tomography', '(', 'CT', ')', 'was', 'performed', 'to', 'detect', 'other', 'injuries', '.']\n",
      "\n",
      "['Maxillofacial', 'CT', 'without', 'contrast', 'showed', 'a', 'comminuted', 'fracture', 'of', 'the', 'left', 'nasal', 'bone', ',', 'a', 'fracture', 'of', 'the', 'medial', 'orbital', 'wall', 'with', 'sagging', 'of', 'medial', 'rectus', 'muscle', 'into', 'the', 'fracture', 'space', ',', 'medial', 'rectus', 'muscle', 'hematoma', ',', 'fracture', 'of', 'lacrimal', 'bone', 'and', 'displacement', 'of', 'piece', 'of', 'it', 'into', 'the', 'orbit', ',', 'left', 'preseptal', 'hematoma', ',', 'complete', 'opaciﬁcation', 'of', 'left', 'intraocular', 'content', ',', 'crystalline', 'lens', 'was', 'not', 'identiﬁed', ',', 'and', 'the', 'eye', 'appeared', 'as', 'one', 'chamber', 'with', 'loss', 'of', 'the', 'eyewall', 'integrity', '(', 'Fig', '.']\n",
      "\n",
      "['2', ')', '.']\n",
      "\n",
      "['Although', 'the', 'left', 'optic', 'nerve', 'appeared', 'stretched', ',', 'there', 'were', 'no', 'obvious', 'CT', 'ﬁndings', 'for', 'its', 'injury', '.']\n",
      "\n",
      "['CT', 'angiographic', 'study', 'of', 'the', 'neck', 'arteries', 'showed', 'no', 'evidence', 'of', 'active', 'extravasation', ',', 'dissection', 'or', 'thrombosis', '.']\n",
      "\n",
      "['Prophylactic', 'antibiotic', 'using', 'intravenous', 'ceftriaxone', 'and', 'metronidazole', 'was', 'commenced', '.']\n",
      "\n",
      "['The', 'patient', 'was', 'taken', 'to', 'the', 'operation', 'room', ',', 'and', 'the', 'wounds', 'were', 'explored', 'and', 'debrided', 'under', 'general', 'anesthesia', '.']\n",
      "\n",
      "['Upper', 'lid', '(', '2', 'cm', ')', 'full', 'thickness', 'laceration', ',', 'eyebrow', '(', '3.5', 'cm', ')', ',', 'lateral', 'to', 'lateral', 'canthal', 'area', 'laceration', 'and', 'inferior', 'bulbar', 'conjunctiva', 'were', 'repaired', '.']\n",
      "\n",
      "['There', 'was', 'a', 'massive', 'corneal', 'laceration', 'with', 'expulsion', 'of', 'the', 'eye', 'content', '.']\n",
      "\n",
      "['Salvaging', 'the', 'left', 'eye', 'was', 'not', 'possible', ',', 'and', 'evisceration', 'of', 'the', 'eye', 'was', 'performed', '.']\n",
      "\n",
      "['Intraoperative', 'examination', 'of', 'the', 'left', 'cheek', 'wound', 'site', '(', 'Fig', '.']\n",
      "\n",
      "['3', ')', 'revealed', 'macerated', 'muscle', 'with', 'a', 'deep', 'wound', 'penetrating', 'the', 'underlying', 'superﬁcial', 'musculoaponeurotic', 'system', '.']\n",
      "\n",
      "['The', 'left', 'Parotid', 'duct', 'was', 'partially', 'transected', 'over', 'the', 'masseter', 'muscle', '(', 'Fig', '.']\n",
      "\n",
      "['3', ')', '.']\n",
      "\n",
      "['This', 'was', 'approximated', 'and', 'primarily', 'repaired', 'using', 'Nylon', '8/0', 'sutures', ',', 'and', 'the', 'parotid', 'gland', 'capsule', 'was', 'also', 'sutured', '.']\n",
      "\n",
      "['The', 'buccal', 'branch', 'of', 'the', 'facial', 'nerve', 'could', 'not', 'be', 'identiﬁed', '.']\n",
      "\n",
      "['The', 'nasal', 'bone', 'fracture', 'was', 'managed', 'with', 'closed', 'reduction', '.']\n",
      "\n",
      "['The', 'lacerations', 'of', 'the', 'left', 'auricle', 'and', 'the', 'left', 'submandibular', 'region', 'were', 'closed', 'in', 'layers', '.']\n",
      "\n",
      "['On', 'a', 'postoperative', 'day', '6', ',', 'the', 'patient', 'developed', 'a', 'small', 'left-sided', 'sialocele', 'which', 'has', 'rapidly', 'progressed', 'into', 'a', 'ﬁstula', '.']\n",
      "\n",
      "['This', 'was', 'managed', 'with', 'Hyoscine', 'tablets', ',', 'transdermal', 'scopolamine', ',', 'and', 'pressure', 'dressing', '.']\n",
      "\n",
      "['A', 'favorable', 'response', 'was', 'observed', 'after', 'three', 'days', '.']\n",
      "\n",
      "['The', 'patient', 'was', 'discharged', 'home', 'on', 'day', '9', 'in', 'a', 'good', 'general', 'condition', 'and', 'was', 'placed', 'on', 'Clindamycin', '600', 'mg', '4', 'times', 'a', 'day', ',', 'Hyoscine', '20', 'mg', '3', 'times', 'a', 'day', ',', 'and', 'Erythromycin', '0.5', '%', 'ophthalmic', 'ointment', '.']\n",
      "\n",
      "['A', 'follow', 'up', 'at', 'one', 'month', 'showed', 'a', 'satisfactory', 'scar', ',', 'completely', 'healed', 'salivary', 'ﬁstula', ',', 'and', 'a', 'residual', 'weak', 'upper', 'lip', 'function', '.']\n",
      "\n",
      "['The', 'patient', 'gave', 'written', 'informed', 'consent', 'for', 'publication', 'of', 'his', 'clinical', 'images', 'in', 'this', 'manuscript', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = \"A 25-year-old male camel caregiver presented to the Emergency Department of Al-Ain Hospital 1 h after being bitten several times in the left side of his head and neck by a 15-year-old male camel. The injury occurred in the farm while the patient was trying to feed the camel. The camel turned aggressive and strongly and repeatedly gripped the patient's face between its jaws, lifting the patient up in the air while shaking and throwing him forcefully to the ground. These bites were repeated four times to the patient's face and neck. The patient was able to rescue himself only after putting his headscarf inside the camel's mouth. On clinical examination, the patient was fully conscious, alert, but in severe distress. His blood pressure was 159/91 mm Hg. Pulse rate was 47 beats per minute, and body temperature was 36.5 °C. There were multiple puncture and laceration wounds on the left side of his face and neck (Fig. 1). Inspection of the facial wounds showed a swollen left eye with lacerations on the eyelid and eyebrow with extensive sub-conjunctival hemorrhage. An approximately 13 cm lacerated wound on the left side of the face extended from the temporal region to the left chin with surrounding skin erythema. There was bleeding from the left ear with a laceration of the crus of the left helix. Neck inspection showed a 7 cm laceration in the left submandibular area with no obvious injury to the adjacent great vessels (Fig. 1). The patient was given 0.5 ml of tetanus toxoid vaccine intramuscularly and was admitted to the hospital. A trauma computed tomography (CT) was performed to detect other injuries. Maxillofacial CT without contrast showed a comminuted fracture of the left nasal bone, a fracture of the medial orbital wall with sagging of medial rectus muscle into the fracture space, medial rectus muscle hematoma, fracture of lacrimal bone and displacement of piece of it into the orbit, left preseptal hematoma, complete opaciﬁcation of left intraocular content, crystalline lens was not identiﬁed, and the eye appeared as one chamber with loss of the eyewall integrity (Fig. 2). Although the left optic nerve appeared stretched, there were no obvious CT ﬁndings for its injury. CT angiographic study of the neck arteries showed no evidence of active extravasation, dissection or thrombosis. Prophylactic antibiotic using intravenous ceftriaxone and metronidazole was commenced. The patient was taken to the operation room, and the wounds were explored and debrided under general anesthesia. Upper lid (2 cm) full thickness laceration, eyebrow (3.5 cm), lateral to lateral canthal area laceration and inferior bulbar conjunctiva were repaired. There was a massive corneal laceration with expulsion of the eye content. Salvaging the left eye was not possible, and evisceration of the eye was performed. Intraoperative examination of the left cheek wound site (Fig. 3) revealed macerated muscle with a deep wound penetrating the underlying superﬁcial musculoaponeurotic system. The left Parotid duct was partially transected over the masseter muscle (Fig. 3). This was approximated and primarily repaired using Nylon 8/0 sutures, and the parotid gland capsule was also sutured. The buccal branch of the facial nerve could not be identiﬁed. The nasal bone fracture was managed with closed reduction. The lacerations of the left auricle and the left submandibular region were closed in layers. On a postoperative day 6, the patient developed a small left-sided sialocele which has rapidly progressed into a ﬁstula. This was managed with Hyoscine tablets, transdermal scopolamine, and pressure dressing. A favorable response was observed after three days. The patient was discharged home on day 9 in a good general condition and was placed on Clindamycin 600 mg 4 times a day, Hyoscine 20 mg 3 times a day, and Erythromycin 0.5% ophthalmic ointment. A follow up at one month showed a satisfactory scar, completely healed salivary ﬁstula, and a residual weak upper lip function. The patient gave written informed consent for publication of his clinical images in this manuscript.\"\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    print(words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/carlitos/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
